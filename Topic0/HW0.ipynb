{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AM50 Homework 0\n",
    "\n",
    "**Name:**\n",
    "\n",
    "**Email:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc(\"text\", usetex=False)\n",
    "rc(\"font\", family = \"serif\")\n",
    "rc(\"figure\",figsize=(9,6))\n",
    "rc(\"figure\",facecolor=\"white\")\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "**Part a.** Give an example of a network model that could be used to describe something you are interested in. What do the nodes represent? What do the edges represent? Is the graph directed or undirected?\n",
    "\n",
    "**Part b.** Sketch a few nodes (at least 5) of this graph and label them. Draw edges which are a part of the network. Is this subgraph connected? ( If you are feeling fancy you could look into using [daft](http://daft-pgm.org) to render the graph in python. Type `pip install daft` at the command line to install daft) This is already installed on the jupyterhub instance on canvas.\n",
    "\n",
    "**Part c.** Is there a meaning to a walk through this graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Movie Stars\n",
    "\n",
    "Run the code below to load in a actor co-starring dataset, don't worry if you don't understand it yet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell's code and all the data comes from https://www.kaggle.com/s7uff3r/network-mapping-hollywood-actor-overlap/data\n",
    "import pandas as pd\n",
    "import json\n",
    "def load_tmdb_credits(path):\n",
    "    df = pd.read_csv(path)\n",
    "    json_columns = ['cast', 'crew']\n",
    "    for column in json_columns:\n",
    "        df[column] = df[column].apply(json.loads)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = load_tmdb_credits(\"tmdb_5000_credits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is somewhat confusing because both the movies and actors in the dataset are referenced by arbitrary id numbers.\n",
    "Here we create new dictionaries -- the lookups -- that reindex the actors and the movies by numbers from 0 to N-1.\n",
    "We only look at the first 5 listed actors from each movie\n",
    "\"\"\"\n",
    "max_actors = 5\n",
    "actor_converter = {} #given actor id -> new id\n",
    "movie_lookup = {}#new id -> Title\n",
    "movie_actors = {}# new movie id -> new actor ids\n",
    "actor_lookup = {} #new id -> name\n",
    "actor_count = 0\n",
    "for i,movie in movie_data.iterrows():\n",
    "    movie_lookup[i] = movie['title']\n",
    "    movie_actors[i] = []\n",
    "    for actor in movie['cast']:\n",
    "        if actor['order']<max_actors:\n",
    "            aid = actor['id']\n",
    "            if aid not in actor_converter:\n",
    "                actor_converter[aid] = actor_count\n",
    "                actor_count += 1\n",
    "            movie_actors[i].append(actor_converter[aid])\n",
    "            actor_lookup[actor_converter[aid]] = actor['name']\n",
    "\n",
    "N_actors = len(actor_lookup)\n",
    "N_movies = len(movie_lookup)\n",
    "print(N_actors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is a little complicated but the end result is three *dictionaries* that contain all the important information for the problem at hand. \n",
    "\n",
    "`movie_lookup` will tell you the name of a given movie, we will refer to all the movies by an id number that originates from the dataset we collected\n",
    "\n",
    "`actor_lookup` is the same deal except it returns an actors name given an actor's id number. These will just be nice to look at predictions of the model.\n",
    "\n",
    "***This is the most important part***\n",
    "\n",
    "`movie_actors`  This is a dictionary that given a movie id number, returns a list of 10 actor id numbers corresponding to the first 10 actors who appear in the credits of that movie. \n",
    "\n",
    "A few examples of querying these dictionaries are given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (movie_lookup[214])\n",
    "print (actor_lookup[8784])\n",
    "print (movie_actors[214])\n",
    "#To get an idea of why these dictionaries are nice\n",
    "print (f\"Movie Title: {movie_lookup[500]}\")\n",
    "print(\"Starring: \")\n",
    "for actor in movie_actors[500]:\n",
    "    print(actor_lookup[actor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part a. ###\n",
    "\n",
    "Now to the actual problem! Use the `movie_actors` dictionary to create the adjacency matrix for this network. Recall that for this case. the $(i,j)$ element of the adjacency matrix $A$ will contain the number 1 if actors $i$ and $j$ have appeared together in a movie. \n",
    "\n",
    "The actors are all indexed by a number in between 0 and `N_actors-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adj = np.zeros((N_actors, N_actors))\n",
    "for movie in range(N_movies):\n",
    "    for i,actor in enumerate(movie_actors[movie]):\n",
    "        for j,costar in enumerate(movie_actors[movie][i+1:]):\n",
    "            #Fill in the elements of the adjacency matrix here\n",
    "            pass #Delete this when you fill in the matrix\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.spy(Adj) #Show all the nonzero elements of a matrix aka the sparsity \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b.\n",
    "\n",
    "Calculate the path lengths between each pair of actors using the adjacency matrix. Compute the mean and median path lengths You might start by considering a small graph like the one shown below and seeing what differnt powers of its adjacency matrix tell you about the graph. \n",
    "<center>\n",
    "<img src=\"https://github.com/Hekstra-Lab/AM50-Student-2019/blob/master/images/simple_graph.png?raw=true\" width=\"200\" height=\"200\">\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hints -- Useful commands\n",
    "print (2**3)\n",
    "test_mat = np.array([[1,2],[3,4]])\n",
    "print(test_mat**2)\n",
    "print(test_mat@test_mat)#use @ for matrix multiplication\n",
    "# what is the difference between mat@mat and mat**2?\n",
    "\n",
    "print(np.linalg.matrix_power(test_mat,2))\n",
    "print((test_mat>2).astype(np.float)) #remember that you can apply math operations to whole arrays without looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_adj = np.zeros((4,4))\n",
    "#Fill in the elements manually'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Use plt.imshow to visualize the powers of this matrix.\n",
    "# plt.imshow(small_adj)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separation_matrix = -1*np.ones([N_actors, N_actors]) \n",
    "max_path_length = 10\n",
    "#the i,j element should be the minimum path length between actors i and j\n",
    "#if the i,j element is -1 it means they are not connected after max_path_length steps\n",
    "for i in range(max_path_length):\n",
    "    #Code to compute path lengths between nodes\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c.\n",
    "\n",
    "Compute the degree distribution for this network by making a histogram of the number of edges connected to each node. What is the average degree for this graph? What about the median? Explain the difference between the two.\n",
    "\n",
    "Hints: \n",
    "1. How do you get the number of edges that a single node has from the adjacency matrix (use `Adj` determined in problem 2a)? \n",
    "2. To plot the histogram modify the example code below.\n",
    "```\n",
    "# Make a histogram \n",
    "bins = np.arange(12)-0.5\n",
    "plt.hist(N_edges,range=[0,12],bins=bins)\n",
    "plt.show()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_edges = np.zeros(N_actors) #number of edges connected to each node\n",
    "for n in range(N_actors): \n",
    "    pass #Your code here\n",
    "#Useful challenge: it is possible to do this without looping by using np.sum() -- do it that way\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the degree distribution on a log-log plot and estimate the exponent by fitting a power law of the form $$P(k)= c\\cdot k^\\alpha$$ to it. Ignore the sharper decay at very high degrees.\n",
    "\n",
    "Hint: If you want to this with points rather than bars follow [this](https://stackoverflow.com/questions/19222711/python-histogram-with-points-and-error-bars) link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part d.\n",
    "\n",
    "Compute the average clustering coefficient for this graph. Recall that for a given node in the graph, the clustering coefficient is the number of edges present among all of its neighbors as a fraction of the maximum possible number of such edges.  It possible to do this with for loops but you can try it using computationally faster numpy indexing, some examples of which are in the cell below (we'll talk more about this in later sections)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint - smart indexing of numpy arrays\n",
    "my_array = np.arange(36).reshape(6,6)\n",
    "print(my_array)\n",
    "print( my_array[ my_array%4 == 0] )\n",
    "rows = np.array([0,2,4])\n",
    "cols = np.array([1,3,5])\n",
    "print(my_array[rows,cols])\n",
    "# For more see https://jakevdp.github.io/PythonDataScienceHandbook/02.07-fancy-indexing.html\n",
    "# Or https://docs.scipy.org/doc/numpy-1.15.0/user/basics.indexing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefs = np.zeros(N_actors)\n",
    "for n in range(N_actors):\n",
    "    #compute the submatrix of Adj containing all neighbors of actor n\n",
    "    #compute the number of edges in this subgraph\n",
    "    #compute the maximum possible number of esges\n",
    "    #compute the clustering coefficient\n",
    "    pass\n",
    "#avg_clustering_coef = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback on Homework\n",
    "These are basically free HW points\n",
    "\n",
    "1. Do you feel this homework contributed to your learning? If not, why not?\n",
    "2. What, if anything, would you change about this problem set?\n",
    "3. Did you find the math and concept or the python implementation be more difficult on this pset? Please rate on a scale of 1 = purely conceptual to 10 purely python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (OPTIONAL) Problem 3 - Simulating the life of Hollywood actors\n",
    "It seems that movie directors sure like to go through the same list of actors all the time, with unknown actors not getting a shot nearly as much as youâ€™d expect by chance. A concept in network analysis, _preferential attachment_, has been proposed to capture this notion in order to explain some features of small-world networks. In this problem we will explore different models for the probability of two actors costaring in a new movie and simulate the co-network based on these probability models. We have written the code that performs the simulations so all you need to provide the probability model $p_m(v)$ of actor $v$ being cast in movie $m$. \n",
    "\n",
    "To be explicit, the network we are considering will have nodes of actors with an edge between them if they have ever costarred in a movie. The adjacency matrix will describe this network, and at the beginning there will be no edges in the graph. We will then start to cast 10 actors to a movies one at a time, only updating the adjacency matrix after a movie is finished, with the movies also being cast one after the other. This will allow us to base the probability of an actor being cast into a movie on who has already been cast for that movie and the adjacency matrix. We can write this as:\n",
    "\\begin{equation}\n",
    "p_m(v|\\text{current cast}, \\text{adjacency matrix}) = ....\n",
    "\\end{equation}\n",
    "which you read out loud as: the probability of actor $v$ being cast in movie $m$ conditioned on the current cast and adjacency matrix. \n",
    "\n",
    "\n",
    "### Part a.\n",
    "We will assume that the probability that actor $v$ will get cast in movie $m$ is determined by two terms: a small probability to get picked at random, and a term proportional to how many other movies you have starred in ($n(v)$). That is, the probability : $p_m(v) \\propto n_0 + n(v)$. We will look at what the co-starring network looks like after $N_{movies} = 300$ movies, each casting 10 actors out of $N_{actors}=1000$ total.\n",
    "\n",
    "**Implement this function in python, being sure to normalize the probability distribution at the end.**\n",
    "\n",
    "\n",
    "Hint 1: We wrote an example python function returning probabilities for a silly model. Spend some time looking at it before you start.  \n",
    "Hint 2: The degree of each actor can be found by summing each row (squishing horizontally). Here is an example:\n",
    "$$M=\\begin{bmatrix}\n",
    "    0       & 1 &2 \\\\\n",
    "    1      & 0 & 1 \\\\\n",
    "    1      & 0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$M\\text{.sum}(axis=1)=\\begin{bmatrix}\n",
    "    3   \\\\\n",
    "    2      \\\\\n",
    "    1      \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example function returning probabilties\n",
    "\n",
    "Here I wrote an example python function. This function implements the \n",
    "\\begin{equation}\n",
    "p_m(v) \\propto \\displaystyle\\sum_{j\\text{ } s.t. A_{ij}\\neq 0} \\sin^2(j)\n",
    "\\end{equation}\n",
    "\n",
    "where $A_{ij}$ refers to the i,jth element of the adjacency matrix and $s.t.=$such that. This function isn't actually justifiable as the actor indices are arbitary, but it does have the key feature of not directly giving away one of the answers to the below problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_get_actor_probs(current_movie_cast, adjacency_matrix):\n",
    "    \"\"\"\n",
    "    \n",
    "    This is a docstring, text that describes the function. We write docstrings that are inspired\n",
    "    by the numpy convention (https://numpydoc.readthedocs.io/en/latest/format.html) we recommend you do this as\n",
    "    well\n",
    "    \n",
    "    inputs\n",
    "    ------\n",
    "    current_movie_cast : list \n",
    "        list the actors already cast into the movie being casted for. Be careful, this \n",
    "        can have length anywhere from 0 to 10.\n",
    "    \n",
    "    adjacency_matrix    : np.array\n",
    "        current adjaceny matrix \n",
    "    \n",
    "    scenario : int\n",
    "        Integer describing \n",
    "    \n",
    "    returns \n",
    "    -------\n",
    "    array  \n",
    "        probability of every actor to be cast in the current movie. the ith element should\n",
    "        be a normalized probability of the ith actor being cast in this movie. If an actor is already\n",
    "        in the movie they should have probabilty 0 so they aren't cast twice!\n",
    "    \"\"\"\n",
    "    \n",
    "    N = adjacency_matrix.shape[0] #get number of actors\n",
    "    if len(cur_cast)==0:\n",
    "        # if no one has been cast yet set random probabilities\n",
    "        p = np.random.rand(N)\n",
    "    else:\n",
    "        #if at least one person has already been cast we can use that\n",
    "        # to inform our next choices\n",
    "        #\n",
    "        # In this example we'll use the somewhat \n",
    "        # ridiculous function sin^2(id number of the actors we are connected to)\n",
    "        p = np.zeros(N) # init with zero prob\n",
    "        p += .000001 #for numerical stability\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if i == j:\n",
    "                    # skip if i=j\n",
    "                    # see https://docs.python.org/3/tutorial/controlflow.html#break-and-continue-statements-and-else-clauses-on-loops\n",
    "                    continue\n",
    "                if adjacency_matrix[i,j]>1:\n",
    "                    p[i] = p[i] + np.sin(j)**2\n",
    "        # To make sure that we don't cast the same person twice set \n",
    "        # the probabilty of anyone already in the movie to 0\n",
    "        # You can use the below line in all the functions you write\n",
    "        # to understand it read about numpy indexing\n",
    "        # https://www.tutorialspoint.com/numpy/numpy_indexing_and_slicing.htm\n",
    "        p[current_movie_cast]=0\n",
    "    p = p/p.sum() # normalize the distribution\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the simulation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_casting(get_actor_probs,n_actors = 1000, actors_per_movie = 10,n_movies=300):\n",
    "    \"\"\"\n",
    "    function that performs the simulation of casting actors to movies. You need to provide a function that \n",
    "    takes in a current cast list and adjacency matrix and returns a probability for every actor that they will\n",
    "    be cast as well\n",
    "    \n",
    "    example usage\n",
    "    -------------\n",
    "    def probability_model_1(current_movie_cast, adjacency_matrix):\n",
    "        .....\n",
    "    \n",
    "    adj_matrix_1, co_star_1 = simulate_casting(probability_model_1)\n",
    "    # do analysis with adjacency matrix\n",
    "    \n",
    "    inputs\n",
    "    ------\n",
    "    get_actor_probs : function\n",
    "        Function that takes arguments: current_movie_cast, adjacency_matrix\n",
    "    \n",
    "    n_actors : integer\n",
    "        number of actors to simulate\n",
    "    \n",
    "    actors_per_movie : integer\n",
    "        number of actors cast to each movie. Must be > n_actors\n",
    "        \n",
    "    n_movies : integer\n",
    "        number of movies to simulate casting for\n",
    "        \n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    adjacency matrix : array\n",
    "        the adjacency matrix as defined in class for the simulated co-star network\n",
    "    co star counts : array\n",
    "        Same as the adjaceny matrix but with edges weighted by the number of times those actors costarred\n",
    "    \"\"\"\n",
    "\n",
    "    id_list = np.arange(n_actors)\n",
    "    co_star_counts = np.zeros([n_actors,n_actors])\n",
    "    adjacency_matrix = np.zeros_like(co_star_counts)\n",
    "\n",
    "    for m in range(n_movies):\n",
    "        cur_cast = []\n",
    "        while len(cur_cast)<10:\n",
    "            probs = get_actor_probs(cur_cast,adjacency_matrix)\n",
    "            next_actor = np.random.choice(a = id_list,p = probs)\n",
    "            cur_cast.append(next_actor)\n",
    "        # update the adjacency and costar matrices\n",
    "        # note that the the adjacency matrix is not updated during the casting \n",
    "        for i,v in enumerate(cur_cast):\n",
    "            for j in cur_cast[i+1:]:\n",
    "                co_star_counts[v,j] += 1\n",
    "                co_star_counts[j,v] += 1\n",
    "                adjacency_matrix[v,j] = 1\n",
    "                adjacency_matrix[j,v] = 1    \n",
    "    return adjacency_matrix, co_star_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for part a here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor_probs_a(current_movie_cast, adjacency_matrix):\n",
    "    N = adjacency_matrix.shape[0]\n",
    "    return np.ones(N)/N\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b \n",
    "Now come up with a probability that depends on the number of actors previously costarred with who are already in cast in the movie. Write out this function in Latex(or by hand with a picture) and justify the mathematical form in one to two sentences. Then implement this in python as ```get_actor_probs_b```\n",
    "\n",
    "Hint 1: The list of who has already been cast is ```current_movie_cast``` in the example function  \n",
    "Hint 2: If you get an error: ```ValueError: Fewer non-zero entries in p than size``` when you run the simulation code that means in some cases your function has no nonzero entries in the probability list. You can often fix this by adding a very small number conventionally written as $\\epsilon \\approx .00001$ to the probabilities. The idea being that in non-pathological cases this won't effect the answer but it will save you if things start to break down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor_probs_b(current_movie_cast, adjacency_matrix):\n",
    "    N = adjacency_matrix.shape[0]\n",
    "    return np.ones(N)/N\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c\n",
    "Write down a probabilty model that where the probability of selection is random for each round of casting. Then implement this in python as ```get_actor_probs_c```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor_probs_c(current_movie_cast, adjacency_matrix):\n",
    "    N = adjacency_matrix.shape[0]\n",
    "    return np.ones(N)/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part d\n",
    "\n",
    "Come up with your own probability model. Write out this function in Latex(or by hand with a picture) and justify the mathematical form in one to two sentences. Then implement this in python as ```get_actor_probs_d```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor_probs_d(current_movie_cast, adjacency_matrix):\n",
    "    N = adjacency_matrix.shape[0]\n",
    "    return np.ones(N)/N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part e - Analysis\n",
    "Below is code that plots the adjacency matrices for each of the models. Use these plots to answer the following questions\n",
    "\n",
    "\n",
    "- Several of these distributions should be composed of the many sharp peaks with very few counts between them. Why is this occuring?\n",
    "    - Hint: consider if these peaks occur at multiples of some number\n",
    "- Considering the degree distribution for part c, why does using n_movies=2000 change this peakiness \n",
    "    - adj_mat_c, costar_c = simulate_casting(get_actor_probs_c,n_movies=2000)\n",
    "\n",
    "\n",
    "- Which of these degrees distributions imply the presence of very import hubs in the networks.\n",
    "\n",
    "A fun extension of this problem (to be clear, not required for this homework) you can try is to identify hubs and see how that affects the distribution of path lengths. Is are there ever sudden changes in the path length distribution when you remove certain actors?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat_a, costar_a = simulate_casting(get_actor_probs_a)\n",
    "adj_mat_b, costar_b = simulate_casting(get_actor_probs_b)\n",
    "adj_mat_c, costar_c = simulate_casting(get_actor_probs_c)\n",
    "adj_mat_d, costar_d = simulate_casting(get_actor_probs_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This plotting code is based on code from this matplotlib example: https://matplotlib.org/examples/pylab_examples/subplots_demo.html\n",
    "f, axarr = plt.subplots(2, 2,figsize=(16,12))\n",
    "f.suptitle('Adjacency Matrices',fontsize=20)\n",
    "axarr[0, 0].set_title('Part A')\n",
    "axarr[0, 0].matshow(adj_mat_a)\n",
    "\n",
    "axarr[0, 1].set_title('Part B')\n",
    "axarr[0, 1].matshow(adj_mat_b)\n",
    "\n",
    "axarr[1, 0].set_title('Part C')\n",
    "axarr[1, 0].matshow(adj_mat_c)\n",
    "\n",
    "axarr[1, 1].set_title('Part D')\n",
    "axarr[1, 1].matshow(adj_mat_d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees_a = adj_mat_a.sum(axis=1)\n",
    "degrees_b = adj_mat_b.sum(axis=1)\n",
    "degrees_c = adj_mat_c.sum(axis=1)\n",
    "degrees_d = adj_mat_d.sum(axis=1)\n",
    "\n",
    "f, axarr = plt.subplots(2, 2,figsize=(16,12))\n",
    "f.suptitle('Degree Distributions',fontsize=20)\n",
    "\n",
    "\n",
    "axarr[0, 0].set_title('Part A')\n",
    "axarr[0, 0].hist(degrees_a,bins =-0.5+np.arange(degrees_a.max()+2))\n",
    "axarr[0, 0].set_yscale('log')\n",
    "\n",
    "axarr[0, 1].set_title('Part B')\n",
    "axarr[0, 1].hist(degrees_b,bins =-0.5+np.arange(degrees_b.max()+2))\n",
    "axarr[0, 1].set_yscale('log')\n",
    "\n",
    "\n",
    "axarr[1, 0].set_title('Part C')\n",
    "axarr[1, 0].hist(degrees_c,bins =-0.5+np.arange(degrees_c.max()+2))\n",
    "axarr[1,0].set_yscale('log')\n",
    "\n",
    "axarr[1, 1].set_title('Part D')\n",
    "axarr[1, 1].hist(degrees_d,bins =-0.5+np.arange(degrees_d.max()+2))\n",
    "# axarr[1, 1].set_xscale('log')\n",
    "axarr[1, 1].set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
